# Quick Start Guide

## âœ… Files Have Been Reorganized!

Your leave management system is now cleanly organized into separate folders.

---

## ğŸ“ New Structure

```
LlamaParsing/
â”œâ”€â”€ gpt4_system/        â†’ GPT-4 based system (run locally, API key stays safe)
â”œâ”€â”€ ollama_system/      â†’ Ollama based system (can run on GPU server)
â”œâ”€â”€ shared/             â†’ HR policies + .env file
â”œâ”€â”€ docs/               â†’ All documentation
â””â”€â”€ otherfiles/         â†’ Your other projects (llama_parse, LingT, etc.)
```

---

## ğŸš€ How to Run Each System

### GPT-4 System (Recommended - 100% Accurate)

```bash
# Navigate to GPT-4 folder
cd gpt4_system

# Run the demo
python3 leave_app_demo.py
```

**What it does:**
- Uses your OpenAI API key from `../shared/.env`
- Loads HR policies from `../shared/hr_knowledge_base.json`
- Runs 5 test scenarios
- Shows 100% accurate policy evaluations

**Cost:** ~$0.05 for full demo (5 scenarios)

---

### Ollama System (Free but Less Accurate)

```bash
# Make sure Ollama is running
ollama serve &
ollama pull llama3.2:latest

# Navigate to Ollama folder
cd ollama_system

# Run the demo
python3 leave_app_demo_ollama.py
```

**What it does:**
- Uses local Llama 3.2 model (no API key needed)
- Loads HR policies from `../shared/hr_knowledge_base.json`
- Runs same 5 test scenarios
- Shows ~67% accurate evaluations (some errors)

**Cost:** $0 (runs locally)

---

## ğŸ§ª Compare Both Systems

```bash
# From GPT-4 folder
cd gpt4_system
python3 test_gpt4_vs_ollama.py
```

**Output:**
- Side-by-side comparison
- GPT-4: âœ… CORRECT (8 â‰¤ 15 = TRUE)
- Ollama: âŒ WRONG (claimed 8 > 15)
- Saves results to `gpt4_vs_ollama_comparison.json`

---

## ğŸ“Š Which Should You Use?

### Use GPT-4 System If:
- âœ… You need 100% accuracy (production)
- âœ… Cost is acceptable ($0.01/request)
- âœ… You have internet connection
- âœ… HR/legal compliance is critical

### Use Ollama System If:
- âœ… You want free inference
- âœ… You need 100% privacy (local only)
- âœ… You're willing to fine-tune for accuracy
- âœ… You have a GPU available

---

## ğŸ”’ Security Reminder

**Your API key is in:** `shared/.env`

âœ… **SAFE to do:**
- Run GPT-4 system locally on your Mac
- Upload Ollama system to GPU server

âŒ **NEVER do:**
- Upload `shared/.env` to GPU server
- Commit `.env` to git
- Share `.env` with anyone

See [docs/SECURE_DEPLOYMENT.md](docs/SECURE_DEPLOYMENT.md) for details.

---

## ğŸ“– Documentation

All guides are in the `docs/` folder:

| Guide | What It Covers |
|-------|----------------|
| [GPT4_VS_OLLAMA_REPORT.md](docs/GPT4_VS_OLLAMA_REPORT.md) | Accuracy comparison, cost analysis |
| [CLOUD_GPU_DEPLOYMENT.md](docs/CLOUD_GPU_DEPLOYMENT.md) | Deploy to Vast.ai/RunPod ($0.09/hr) |
| [SECURE_DEPLOYMENT.md](docs/SECURE_DEPLOYMENT.md) | Keep your API keys safe |
| [GPU_SERVER_LEARNING_GUIDE.md](docs/GPU_SERVER_LEARNING_GUIDE.md) | 8 experiments to learn AI/ML |
| [FINE_TUNING_GUIDE.md](docs/FINE_TUNING_GUIDE.md) | Improve Ollama to 95%+ accuracy |

---

## ğŸ¯ Recommended Next Steps

### 1. Test GPT-4 Locally (5 minutes)
```bash
cd gpt4_system
python3 leave_app_demo.py
```
**Result:** See perfect accuracy on all 5 scenarios

### 2. Read the Comparison Report (5 minutes)
```bash
cat docs/GPT4_VS_OLLAMA_REPORT.md
```
**Learn:** Why GPT-4 is 100% accurate vs Ollama's 67%

### 3. Decide on Deployment
- **Production?** â†’ Use GPT-4 locally
- **Learning?** â†’ Try GPU server experiments
- **Cost-sensitive?** â†’ Fine-tune Ollama first

---

## ğŸ’¡ Common Questions

**Q: Where is my HR knowledge base?**
A: `shared/hr_knowledge_base.json`

**Q: Where is my API key?**
A: `shared/.env` (keep it safe!)

**Q: Can I run GPT-4 on GPU server?**
A: Yes, but unnecessary (wastes GPU, API key at risk). Run it locally instead.

**Q: Can I run Ollama on GPU server?**
A: Yes! This is safe (no API keys). See [CLOUD_GPU_DEPLOYMENT.md](docs/CLOUD_GPU_DEPLOYMENT.md)

**Q: Which system is production-ready?**
A: GPT-4 (100% accuracy). Ollama needs fine-tuning first.

**Q: How much does GPT-4 cost?**
A: ~$0.01 per request = $10-20/year for 1000 requests

---

## ğŸš¨ Troubleshooting

### "ModuleNotFoundError: No module named 'openai'"
```bash
pip install openai python-dotenv
```

### "Error: OPENAI_API_KEY not found"
```bash
# Make sure shared/.env exists with:
# OPENAI_API_KEY=sk-proj-...
```

### "Ollama connection refused"
```bash
# Start Ollama first
ollama serve &
ollama pull llama3.2:latest
```

### "Import paths not working"
```bash
# Always run from the system folder:
cd gpt4_system     # for GPT-4
cd ollama_system   # for Ollama
```

---

## ğŸ“¦ File Organization Summary

**Before reorganization:**
```
LlamaParsing/
â”œâ”€â”€ leave_management_agent.py
â”œâ”€â”€ leave_management_agent_ollama.py
â”œâ”€â”€ leave_app_demo.py
â”œâ”€â”€ leave_app_demo_ollama.py
â”œâ”€â”€ ... (all files mixed together)
```

**After reorganization:**
```
LlamaParsing/
â”œâ”€â”€ gpt4_system/          â† GPT-4 files
â”œâ”€â”€ ollama_system/        â† Ollama files
â”œâ”€â”€ shared/               â† Common resources
â”œâ”€â”€ docs/                 â† All documentation
â””â”€â”€ otherfiles/           â† Other projects
```

**Benefits:**
- âœ… Clear separation of systems
- âœ… Easy to deploy just one system
- âœ… No confusion about which files to use
- âœ… API key safely in shared/ folder
- âœ… Documentation organized in docs/

---

## âœ… You're All Set!

**To get started right now:**
```bash
cd gpt4_system
python3 leave_app_demo.py
```

Enjoy your clean, organized project! ğŸ‰
